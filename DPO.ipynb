{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w7M3hDsiY9UF",
    "outputId": "a1efa27f-8bab-4383-f145-ab4394a9e10a"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "njbSXmDyZFp3",
    "outputId": "048974a1-873a-41fd-b122-09324a76daf3"
   },
   "outputs": [],
   "source": [
    "!pip install \"unsloth[torch]\" trl datasets accelerate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RLqwtj22aTMH"
   },
   "outputs": [],
   "source": [
    "sft_model_path = \"/content/drive/MyDrive/tinyllama-lora-sft-tuned-model\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vLe_XrjuaVyJ",
    "outputId": "5f644ae0-67e1-4ebf-8246-c67db269f255"
   },
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "from datasets import load_dataset\n",
    "import torch \n",
    "\n",
    "# Load model and tokenizer from your fine-tuned path\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=sft_model_path,\n",
    "    dtype=torch.float16, \n",
    "    load_in_4bit=True  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z5i6Ta5wakVo",
    "outputId": "b91440db-5c9c-4509-bef4-f06eda13ae2d"
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"yitingxie/rlhf-reward-datasets\", split=\"train\").select(range(10000))\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07mSQvCyavAv"
   },
   "outputs": [],
   "source": [
    "training_args = DPOConfig(\n",
    "    output_dir=\"/content/drive/MyDrive/tinyllama-dpo-trained\",\n",
    "    logging_steps=100,\n",
    "    bf16=False, \n",
    "    per_device_train_batch_size=8,\n",
    "    gradient_accumulation_steps=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLmDLXhYazfd"
   },
   "outputs": [],
   "source": [
    "trainer = DPOTrainer(model=model, args=training_args, processing_class=tokenizer, train_dataset=dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ffb82ba9feac4e8aa5a930e37cb20636",
      "1ed876bbfb2b4ecdbe506832eb5137d9",
      "05c302a040f941c2b4706771ac52360b",
      "3f221ca372764f3cb492488f1c9867a3",
      "ba337e15e9894f0eafe33e574b956062",
      "7616bfd9fceb4285a409ddbbc86663cb",
      "b401cb73f7a74ce7bd2acdfc0adeaa4d",
      "58aef85199b04f89bc099ab432438b3a",
      "4a1ec29a23e64059bd994b9702fc2d84",
      "efa8883d2515484c886368c14ac1572b",
      "32bc8bac16b3406b84ff466ddb442f6d"
     ]
    },
    "id": "OHzfNniqbXek",
    "outputId": "768f45cf-c1f4-4fb3-e8a2-5fe999b64fe1"
   },
   "outputs": [],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nh0mUudNnjBE",
    "outputId": "6beef0d1-404f-4ea4-fd17-15e13d707c50"
   },
   "outputs": [],
   "source": [
    "# Load the model with adapters (same as before)\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"/content/drive/MyDrive/tinyllama-dpo-trained/checkpoint-3750\",  # Use final checkpoint\n",
    "    dtype=torch.float16,\n",
    "    load_in_4bit=False  # Set to False before merging\n",
    ")\n",
    "\n",
    "# ✅ Merge the LoRA adapters into the base model\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# ✅ Save the merged model and tokenizer\n",
    "save_path = \"/content/drive/MyDrive/tinyllama-dpo-merged-final\"\n",
    "model.save_pretrained(save_path)\n",
    "tokenizer.save_pretrained(save_path)\n",
    "\n",
    "print(f\"✅ Final merged model saved to: {save_path}\")\n",
    "\n",
    "\"\"\"\n",
    "So I have trained the SFT model with LoRA adapters\n",
    "and in DPO we trained the same SFT model with reward data (still using LoRA)\n",
    "then finally we merged the adapters into the base model\n",
    "so the final model has:\n",
    "\n",
    "base TinyLlama knowledge\n",
    "SFT instruction knowledge\n",
    "reward-based DPO tuning”\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "name": "Making the Most of your Colab Subscription",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
